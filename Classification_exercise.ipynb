{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuX4Tmgp0MZE"
      },
      "source": [
        "# Data inputs and Display Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bJmiGN30MZM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEWZSOQa6sip"
      },
      "outputs": [],
      "source": [
        "#Installing Libraries\n",
        "!pip install sweetviz\n",
        "!pip install shap\n",
        "!pip install unrar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8QzNHXF0MZQ"
      },
      "source": [
        "# EDA Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7XAkvTG0MZR"
      },
      "outputs": [],
      "source": [
        "import sweetviz as sv\n",
        "#!pip install sweetviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJvtYXmD0MZS"
      },
      "source": [
        "# Data Preprocessing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOpf65rB0MZT"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OrdinalEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSvzntbp0MZV"
      },
      "source": [
        "# Feature Selection & Modelling Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEvvp_tN0MZW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLPJz6xc0MZY"
      },
      "source": [
        "# Metrics Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEg3sIlk0MZa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import f1_score\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u3VnhjW0MZd"
      },
      "source": [
        "### Model Explanantion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztarMhL0MZe"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSBIEOu59j3u"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/univai-ghf/Classificationworkshop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcsbVaQE954l"
      },
      "outputs": [],
      "source": [
        "#! unzip -q 'workshop_classification/prep_file.rar' -d 'workshop_classification/prep_file.csv'\n",
        "!unrar x 'Classificationworkshop/prep_file.rar'  'Classificationworkshop'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Run till here"
      ],
      "metadata": {
        "id": "epqzGGEDKjc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8UPEaJM0MZl"
      },
      "outputs": [],
      "source": [
        "t1 = pd.read_csv(\"Classificationworkshop/prep_file.csv\",sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGRhQqws0MZn"
      },
      "source": [
        "# Step 1-  Look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCAFufZ-0MZp"
      },
      "outputs": [],
      "source": [
        "t1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWg4xbf00MZz"
      },
      "outputs": [],
      "source": [
        "#![](./presentation/Capture1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462frsv50MZ2"
      },
      "source": [
        "# Look at data - now to get the target variable distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gytLI6zK0MZ3"
      },
      "outputs": [],
      "source": [
        "t1[\"risk_flag\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFKelz7K0MZ4"
      },
      "outputs": [],
      "source": [
        "t1[\"risk_flag\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtI1C1dJ0MZ5"
      },
      "source": [
        "# Look at data - listing string and numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E7V58uE0MZ6"
      },
      "outputs": [],
      "source": [
        "str_col_name_df = pd.read_csv(\"Classificationworkshop/str_cols.csv\")\n",
        "str_col_name_df.columns = [\"index\",\"col_name\"]\n",
        "str_col_name_list =list(str_col_name_df[\"col_name\"])\n",
        "\n",
        "num_col_name_df = pd.read_csv(\"Classificationworkshop/num_cols.csv\")\n",
        "num_col_name_df.columns = [\"index\",\"col_name\"]\n",
        "num_col_name_df=num_col_name_df.reset_index()\n",
        "num_col_name_list = list(num_col_name_df[\"col_name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvTTjKF80MZ7"
      },
      "outputs": [],
      "source": [
        "print (str_col_name_list)\n",
        "print (num_col_name_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TWi2WUg0MZ7"
      },
      "outputs": [],
      "source": [
        "####Back to Slide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIXHKBmB0MZ9"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8xmqugn0MZ-"
      },
      "outputs": [],
      "source": [
        "sweet_report = sv.analyze([t1,\"full_data\"],target_feat=\"risk_flag\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DtWKNfr0MZ-"
      },
      "outputs": [],
      "source": [
        "sweet_report.show_html('sweet_report.html')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 mins to run the code"
      ],
      "metadata": {
        "id": "s7TkzJZUKO6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmtnE-M6D7kf"
      },
      "outputs": [],
      "source": [
        "t0 = t1.copy()\n",
        "for i in str_col_name_list:\n",
        "    t1[i] = t1[i].str.lower().str.lstrip().str.rstrip()\n",
        "    t1[i] = t1[i].str.replace(\"[^a-z\\s]+\",\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAyf5Ool0MZ_"
      },
      "outputs": [],
      "source": [
        "####back to slide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MszhUfbH0MaA"
      },
      "source": [
        "# Train test split\n",
        "### Before we do any preprocessing we want to keep train and test seperate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvjrT_150MaA"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(t1, t1[\"risk_flag\"], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH-aqvxd0MaB"
      },
      "outputs": [],
      "source": [
        "x_train0 = x_train.reset_index()\n",
        "x_test0 = x_test.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbiFI81Z-9oc"
      },
      "outputs": [],
      "source": [
        "x_train0.shape, x_test0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Label encoding string Variables -- baseline categorical approach"
      ],
      "metadata": {
        "id": "WDxrEwWRIfSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "\n",
        "x_train_str= pd.DataFrame(enc.fit_transform(x_train0[str_col_name_list]))\n",
        "x_test_str = pd.DataFrame(enc.transform(x_test0[str_col_name_list]))"
      ],
      "metadata": {
        "id": "KiDmJn_4SrLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz1 = x_train_str.head()\n",
        "viz1 = viz1.astype(int)\n",
        "viz1.columns = str_col_name_list\n",
        "viz1"
      ],
      "metadata": {
        "id": "zCCvQ2ah6m8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_str.shape"
      ],
      "metadata": {
        "id": "8AQThQ4u2Wqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc.categories_"
      ],
      "metadata": {
        "id": "KwCHBa0H2Kup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenating Numeric and categorical"
      ],
      "metadata": {
        "id": "KqFrxFzyJkqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_train1 = pd.concat([x_train_str,x_train0[num_col_name_list]],axis=1)\n",
        "df_all_test1 = pd.concat([x_test_str,x_test0[num_col_name_list]],axis=1)"
      ],
      "metadata": {
        "id": "nZBT8LImOq-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel_cols = str_col_name_list + num_col_name_list"
      ],
      "metadata": {
        "id": "5Geu3j5s2H5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##back to presentation"
      ],
      "metadata": {
        "id": "CUtR7RjKHCcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nHwwAlhUJsbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Model"
      ],
      "metadata": {
        "id": "x_7IZfNVJsn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_train1 = le.fit_transform(y_train)\n",
        "y_test1 = le.transform(y_test)"
      ],
      "metadata": {
        "id": "ToMEyo4Hds5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = [0.1,0.9]\n",
        "\n",
        "\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=300,max_depth= 5,subsample= 0.2,class_weights = class_weights,scale_pos_weight=6,\n",
        "                    colsample_bytree= 0.3)\n",
        "xgb.fit(df_all_train1,y_train1)\n"
      ],
      "metadata": {
        "id": "gX7uD7afOY9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##back to presentation"
      ],
      "metadata": {
        "id": "bO42zKl3HKff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measure"
      ],
      "metadata": {
        "id": "dZVqqH2oJyvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sacus2BZ0Mag"
      },
      "outputs": [],
      "source": [
        "def cf_mat_conv(cf_mat):\n",
        "    cf_mat1 = pd.DataFrame(cf_mat)\n",
        "\n",
        "    \n",
        "    cols0 = cf_mat1.columns\n",
        "    #print (cols0)\n",
        "    cols1 = []\n",
        "    rows1 = []\n",
        "    for i in cols0:\n",
        "        i1 = \"pred_\" + str(i)\n",
        "        i2 = \"actual_\" + str(i)\n",
        "        cols1.append(i1)\n",
        "        rows1.append(i2)\n",
        "    #print (rows1)\n",
        "    cf_mat1.columns = cols1\n",
        "    cf_mat1[\"vals\"] = rows1\n",
        "    return cf_mat1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics1(mod1,test_set,actual1,fg):\n",
        "    mod = eval(mod1)\n",
        "    pred=mod.predict(test_set)\n",
        "    #print(pred)\n",
        "    pred1=mod.predict_proba(test_set)[:,1]\n",
        "    \n",
        "    ac1 = accuracy_score(actual1, pred)\n",
        "    cf_mat1 = confusion_matrix(actual1, pred, labels=None, sample_weight=None)\n",
        "    cf_mat_orig = cf_mat1.copy()\n",
        "\n",
        "    \n",
        "    #print (b_test_b.shape)\n",
        "    cf_mat1 = cf_mat_conv(cf_mat1)\n",
        "\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(actual1, pred1)\n",
        "    auc_pr = average_precision_score(actual1, pred1)\n",
        "    auc1 = auc(fpr, tpr)\n",
        "    f1scr = f1_score(actual1, pred, average='macro')\n",
        "    \n",
        "    if(fg==1):\n",
        "        pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "    # plot the roc curve for the model\n",
        "        pyplot.plot(fpr, tpr, marker='.')\n",
        "    # show the plot\n",
        "        pyplot.show()\n",
        "\n",
        "        precision, recall, thresholds = precision_recall_curve(actual1, pred1)\n",
        "        pyplot.plot(precision, recall, marker='.')\n",
        "        pyplot.show()\n",
        "\n",
        "        cmd = ConfusionMatrixDisplay(cf_mat_orig)\n",
        "        cmd.plot(values_format='')\n",
        "\n",
        "    return ac1,cf_mat1,auc1,f1scr,auc_pr\n"
      ],
      "metadata": {
        "id": "68H3oeTsjB4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (get_metrics1(\"xgb\",df_all_test1,y_test1,1))"
      ],
      "metadata": {
        "id": "3Ks0Zkf6jEc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##back to presentation"
      ],
      "metadata": {
        "id": "msi_CJvhHUj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaining the Model"
      ],
      "metadata": {
        "id": "34WwWTfDJ4GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1_tr = pd.DataFrame(df_all_train1)\n",
        "df1_tr.columns =sel_cols\n",
        "explainer = shap.TreeExplainer(xgb)\n",
        "shap_values = explainer.shap_values(df1_tr)\n",
        "\n"
      ],
      "metadata": {
        "id": "iNDd8RgWyDAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, df1_tr, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "R3QgMljN4er4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "UvY0WP5SJ98n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding"
      ],
      "metadata": {
        "id": "l5SuBCLcKF2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHotEncoding the data\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "#use fit_transform method of onehotencoder to one hot encode categorical columns of x_train0 and x_test0\n",
        "\n",
        "df_one_hot_tr = pd.DataFrame(.fit_transform(np.array(_____[str_col_name_list])).todense())\n",
        "df_one_hot_te = pd.DataFrame(enc.transform(np.array(x_test0[_________])).todense())\n",
        "colnames = enc.get_feature_names_out()\n",
        "\n",
        "#assign column names of one hot dataframes to colnames\n",
        "df_one_hot_tr.columns = ________\n",
        "df_one_hot_te.columns = ________"
      ],
      "metadata": {
        "id": "rhKdxyNG5WwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the one hot coded training dataframe using .head()\n",
        "df_one_hot_tr.______()"
      ],
      "metadata": {
        "id": "LWq57g9r7Ty5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate one hot encoded colmns to the numerical columns of the train and test data [num_col_name_list] along axis =1\n",
        "df_all_one_hot_train1 = pd.concat([df_one_hot_tr,x_train0[______________]],axis=__)\n",
        "df_all_one_hot_test1 = pd.concat([df_one_hot_te,x_test0[______________]],axis=___)"
      ],
      "metadata": {
        "id": "JUPZ9qNu59wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make a list of all selected columns adding list of colnames and num_col_name_list\n",
        "sel_cols = list(colnames) + ___________"
      ],
      "metadata": {
        "id": "JwHRRBcm6MCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = [0.1,0.9]\n",
        "\n",
        "\n",
        "#Create model instance of XGBClassifier with n_estimators =100, max_depth =5, subsample =0.2, \n",
        "# class_weights as class_weights we created above, scale_pos_weight =6, colsample_bytree = 0.3\n",
        "xgb_ohe = XGBClassifier(n_estimators=____,max_depth= ___,subsample= ____,class_weights = class_weights,scale_pos_weight=___,\n",
        "                    colsample_bytree= ___,n_jobs=6)\n",
        "# for the model on train data(df_all_one_hot_train1 and y_train1)\n",
        "xgb_ohe.fit(________________,______)\n"
      ],
      "metadata": {
        "id": "xQAOrlx1_2O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (get_metrics1(\"xgb_ohe\",df_all_one_hot_test1,y_test1,1))"
      ],
      "metadata": {
        "id": "GI9q0er6_8yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_tr_ohe = pd.DataFrame(df_all_one_hot_train1)\n",
        "df1_tr_ohe.columns =sel_cols\n",
        "\n",
        "#Lets do some XAI using SHAP input the model xgb_ohe in shap.treeexplainer\n",
        "explainer_ohe = shap.TreeExplainer(_____)\n",
        "#input the training dataframe df1_tr_ohe \n",
        "shap_values_ohe = explainer_ohe.shap_values(_______)"
      ],
      "metadata": {
        "id": "XKs14cmFCFss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets make a summary plot of shap_values_ohe, df1_tr_ohe with a \"bar\" plot\n",
        "shap.summary_plot(____________, _________, plot_type=\"___\")"
      ],
      "metadata": {
        "id": "pW7i_60SCbJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Median impute of missing Values"
      ],
      "metadata": {
        "id": "alqz2SS9KQ6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### median impute of missing values"
      ],
      "metadata": {
        "id": "5ADEajc9CiAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create simpleimputer object for replacing nan values with mean [missing_values=np.nan, strategy='mean']\n",
        "imp_mean = SimpleImputer(missing_values=______, strategy='_____')\n",
        "#we can impute numerical columns by this Simple Imputer. So pass numerical columns of x_train0[num_col_name_list]\n",
        "imp_mean.fit(x_train0[____________])\n",
        "#transform both test and train data using imp_mean \n",
        "x_train_num = pd.DataFrame(imp_mean.transform(x_train0[_________]))\n",
        "x_test_num = pd.DataFrame(imp_mean.transform(x_test0[____________]))\n",
        "\n",
        "x_train_num.columns = num_col_name_list\n",
        "x_test_num.columns = num_col_name_list"
      ],
      "metadata": {
        "id": "vN3WrloODoY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate the string columns and the numerical columns of Train and test data along axis =1\n",
        "df_all_imp_train1 = pd.concat([x_train_str,_______],axis=___)\n",
        "df_all_imp_test1 = pd.concat([x_test_str,________],axis=1)"
      ],
      "metadata": {
        "id": "hudqsuYiDwo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = [0.1,0.9]\n",
        "\n",
        "#Create model instance of XGBClassifier with n_estimators =300, max_depth =5, subsample =0.2, \n",
        "# class_weights as class_weights we created above, scale_pos_weight =6, colsample_bytree = 0.3\n",
        "\n",
        "xgb_imp = XGBClassifier(n_estimators=300,max_depth= 5,subsample= 0.2,class_weights = class_weights,scale_pos_weight=6,\n",
        "                    colsample_bytree= 0.3)\n",
        "xgb_imp.fit(df_all_imp_train1,y_train1)"
      ],
      "metadata": {
        "id": "ocB2e4iWt4KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (get_metrics1(\"xgb_imp\",df_all_imp_test1,y_test1,1))"
      ],
      "metadata": {
        "id": "cpoVcvWrvHi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting all it together"
      ],
      "metadata": {
        "id": "ReR5NKImKZzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a dataframe with the metrics : accuracy, auc, f1, auc_pr for the different models we created using different data sets\n",
        "\n",
        "#make a list of datasets created : df_all_test1,df_all_one_hot_test1,df_all_imp_test1\n",
        "df_datasets = [________,________,___________]\n",
        "\n",
        "# loop over the models we created respectively in the list above: \"xgb\",\"xgb_ohe\",\"xgb_imp\"\n",
        "\n",
        "for num,i in enumerate([\"___\",\"_______\",\"___________\"]):\n",
        "    print (num)\n",
        "    ac1,cf_mat1,auc1,f1scr,auc_pr = get_metrics1(i,df_datasets[num],y_test1,0)\n",
        "    \n",
        "    # make a data frame of selected metrics (ac1,auc1,f1scr,auc_pr)\n",
        "    df_met = pd.DataFrame([(__,__,___,____)])\n",
        "    #name the columns of data frame\n",
        "    df_met.columns = [\"accuracy\",\"auc\",\"f1\",\"auc_pr\"]\n",
        "    df_met[\"model\"] = i\n",
        "    \n",
        "    if(num==0):  \n",
        "        df_met_all = df_met\n",
        "    else:\n",
        "        #concatenate the data frames to create one data frame\n",
        "        df_met_all = pd.concat([df_met,df_met_all],axis=0)"
      ],
      "metadata": {
        "id": "bZBdVpuayC4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualise the metrics data frame using .head()\n",
        "df_met_all._____()"
      ],
      "metadata": {
        "id": "pUHrriSz6U9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##back to presentation"
      ],
      "metadata": {
        "id": "Drw4CBFkHeoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Classification_v2_exe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}